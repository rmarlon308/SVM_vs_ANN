library(readr)
library(dplyr)
library(e1071)
library(precrec)
library(vtreat)
library(pROC)
testing = read_csv("/home/marlon/mainfolder/marlon/USFQ/DataMining/10_FinalProject/FP/proyectoFinal/Model_2/dataset/testing.csv")
training = read_csv("/home/marlon/mainfolder/marlon/USFQ/DataMining/10_FinalProject/FP/proyectoFinal/Model_2/dataset/training.csv")
dataset = rbind(training, testing)
dataset$class = as.factor(dataset$class)
#Normalize the data
summary(dataset)
for(i in 2:ncol(dataset)){
dataset[i] =  (dataset[i] - min(dataset[i]))/ (max(dataset[i]) - min(dataset[i])) * (1-0) + 0
}
summary(dataset)
x_data = dataset[, 2:ncol(dataset)]
y_data = dataset[, 1]
#Dimensionality reduction
mean_row = colMeans(x_data)
for(i in 1:nrow(x_data)){
x_data[i, ] = x_data[i, ] - mean_row
}
svd = svd(x_data)
eigVectors = svd$v
eigValues = svd$d^2/sum(svd$d^2)
variance = cumsum(eigValues)/sum(eigValues)
k = NULL
for(i in 1:length(variance)){
if(variance[i] >= 0.95){
k = i
print(k)
break
}
}
k_selected = eigVectors[, 1:k]
proy_data = as.data.frame(as.matrix(x_data) %*% as.matrix(k_selected))
final_data = cbind(y_data, proy_data)
#tunning
gamma_list = 5*10^(-2:2)
cost_list = c(0.01, 0.1, 1, 10, 100)
kernel_list = c("radial", "linear", "polynomial")
splitPlan = kWayCrossValidation(nRows = nrow(final_data), 10, NULL, NULL)
gen_acc = c()
gen_auc = c()
gen_pre = c()
gen_rec = c()
gen_gamma = c()
gen_cost = c()
gen_kernel = c()
for(gm in gamma_list){
for(cos in cost_list){
for(ker in kernel_list){
recall = c()
accuracy = c()
precision = c()
auc = c()
for(i in 1:10){
split = splitPlan[[i]]
svm_model = svm(class~ ., data = final_data[split$train, ], type = "C-classification",
kernel = ker,
cost = cos,
gamma = gm)
pred = predict(svm_model, final_data[split$app, ])
real = final_data[split$app, ]$class
confusion = as.matrix(table(real, pred))
diag = diag(confusion)
colsums = apply(confusion, 2, sum)
rowsums = apply(confusion, 1, sum)
n = sum(confusion)
if(colsums == 0){
print(confusion)
}
recall[i] = diag / rowsums
precision[i] = diag / colsums
accuracy[i] = sum(diag) / n
x = roc(as.numeric(real), (as.numeric(pred) - 1))
auc[i] = x$auc
}
gen_acc = c(gen_acc, mean(accuracy))
gen_auc = c(gen_auc, mean(auc))
gen_pre = c(gen_pre, mean(precision))
gen_rec = c(gen_rec, mean(recall))
gen_gamma = c(gen_gamma, gm)
gen_cost = c(gen_cost, cos)
gen_kernel = c(gen_kernel, ker)
}
}
}
score_svm_2 = data.frame(gen_kernel, gen_gamma, gen_cost, gen_acc, gen_auc, gen_pre, gen_rec)
write_csv(score_svm_2, "/home/marlon/mainfolder/marlon/USFQ/DataMining/10_FinalProject/FP/proyectoFinal/Model_2/score_svm_2.csv")
best_model = score_svm_2 %>%
arrange(desc(gen_auc))
best_model = best_model[1, ]
library(readr)
library(dplyr)
library(e1071)
library(precrec)
library(vtreat)
library(pROC)
testing = read_csv("/home/marlon/mainfolder/marlon/USFQ/DataMining/10_FinalProject/proyectoFinal/Model_2/dataset/testing.csv")
training = read_csv("/home/marlon/mainfolder/marlon/USFQ/DataMining/10_FinalProject/proyectoFinal/Model_2/dataset/training.csv")
dataset = rbind(training, testing)
dataset$class = as.factor(dataset$class)
#Normalize the data
summary(dataset)
for(i in 2:ncol(dataset)){
dataset[i] =  (dataset[i] - min(dataset[i]))/ (max(dataset[i]) - min(dataset[i])) * (1-0) + 0
}
summary(dataset)
x_data = dataset[, 2:ncol(dataset)]
y_data = dataset[, 1]
#Dimensionality reduction
mean_row = colMeans(x_data)
for(i in 1:nrow(x_data)){
x_data[i, ] = x_data[i, ] - mean_row
}
svd = svd(x_data)
eigVectors = svd$v
eigValues = svd$d^2/sum(svd$d^2)
variance = cumsum(eigValues)/sum(eigValues)
k = NULL
for(i in 1:length(variance)){
if(variance[i] >= 0.95){
k = i
print(k)
break
}
}
k_selected = eigVectors[, 1:k]
proy_data = as.data.frame(as.matrix(x_data) %*% as.matrix(k_selected))
final_data = cbind(y_data, proy_data)
#tunning
gamma_list = 5*10^(-2:2)
cost_list = c(0.01, 0.1, 1, 10, 100)
kernel_list = c("radial", "linear", "polynomial")
splitPlan = kWayCrossValidation(nRows = nrow(final_data), 10, NULL, NULL)
gen_acc = c()
gen_auc = c()
gen_pre = c()
gen_rec = c()
gen_gamma = c()
gen_cost = c()
gen_kernel = c()
for(gm in gamma_list){
for(cos in cost_list){
for(ker in kernel_list){
recall = c()
accuracy = c()
precision = c()
auc = c()
for(i in 1:10){
split = splitPlan[[i]]
svm_model = svm(class~ ., data = final_data[split$train, ], type = "C-classification",
kernel = ker,
cost = cos,
gamma = gm)
pred = predict(svm_model, final_data[split$app, ])
real = final_data[split$app, ]$class
confusion = as.matrix(table(real, pred))
diag = diag(confusion)
colsums = apply(confusion, 2, sum)
rowsums = apply(confusion, 1, sum)
n = sum(confusion)
if(colsums == 0){
print(confusion)
}
recall[i] = diag / rowsums
precision[i] = diag / colsums
accuracy[i] = sum(diag) / n
x = roc(as.numeric(real), (as.numeric(pred) - 1))
auc[i] = x$auc
}
gen_acc = c(gen_acc, mean(accuracy))
gen_auc = c(gen_auc, mean(auc))
gen_pre = c(gen_pre, mean(precision))
gen_rec = c(gen_rec, mean(recall))
gen_gamma = c(gen_gamma, gm)
gen_cost = c(gen_cost, cos)
gen_kernel = c(gen_kernel, ker)
}
}
}
score_svm_2 = data.frame(gen_kernel, gen_gamma, gen_cost, gen_acc, gen_auc, gen_pre, gen_rec)
write_csv(score_svm_2, "/home/marlon/mainfolder/marlon/USFQ/DataMining/10_FinalProject/proyectoFinal/Model_2/score_svm_2.csv")
best_model = score_svm_2 %>%
arrange(desc(gen_auc))
View(best_model)
best_model = best_model[1, ]
best_gamma = best_model[, 2]
best_cost = best_model[,3]
best_kernel = best_model[,1]
splitPlan = kWayCrossValidation(nRows = nrow(final_data), 10, NULL, NULL)
recall = c()
accuracy = c()
precision = c()
auc = c()
pred_vector = rep(0, nrow(final_data))
for(i in 1:10){
split = splitPlan[[i]]
svm_model = svm(class~ ., data = final_data[split$train, ], type = "C-classification", kernel = best_kernel,
cost = best_cost,
gamma = best_gamma)
pred_vector[split$app] = predict(svm_model, final_data[split$app, ])
pred = predict(svm_model, final_data[split$app, ])
real = final_data[split$app, ]$class
confusion = as.matrix(table(real, pred))
diag = diag(confusion)
colsums = apply(confusion, 2, sum)
rowsums = apply(confusion, 1, sum)
n = sum(confusion)
recall[i] = diag / rowsums
precision[i] = diag / colsums
accuracy[i] = sum(diag) / n
x = roc(as.numeric(real), (as.numeric(pred) - 1))
auc[i] = x$auc
}
sprintf("Accuracy   Mean: %f   SD: %f", mean(accuracy), sd(accuracy))
sprintf("Precision   Mean: %f   SD: %f", mean(precision), sd(precision))
sprintf("Recall   Mean: %f   SD: %f", mean(recall), sd(recall))
sprintf("AUC   Mean: %f   SD: %f", mean(auc), sd(auc))
real_vector = final_data$class
real_vector = as.numeric(real_vector)
table(pred_vector, real_vector)
roc.multi = multiclass.roc(real_vector, pred_vector)
rs <- roc.multi[['rocs']]
plot.roc(rs[[1]])
roc.curve(real_vector, pred_vector)
library(readr)
library(dplyr)
library(keras)
library(tensorflow)
testing = read_csv("/home/marlon/mainfolder/marlon/USFQ/DataMining/10_FinalProject/proyectoFinal/Model_2/dataset/testing.csv")
training = read_csv("/home/marlon/mainfolder/marlon/USFQ/DataMining/10_FinalProject/proyectoFinal/Model_2/dataset/training.csv")
dataset = rbind(training, testing)
dataset$class = as.factor(dataset$class)
dataset$class = as.numeric(dataset$class) - 1
#Normalize the data
summary(dataset)
for(i in 2:ncol(dataset)){
dataset[i] =  (dataset[i] - min(dataset[i]))/ (max(dataset[i]) - min(dataset[i])) * (1-0) + 0
}
summary(dataset)
x_data = dataset[, 2:ncol(dataset)]
y_data = dataset[, 1]
#Dimensionality reduction
mean_row = colMeans(x_data)
for(i in 1:nrow(x_data)){
x_data[i, ] = x_data[i, ] - mean_row
}
svd = svd(x_data)
eigVectors = svd$v
eigValues = svd$d^2/sum(svd$d^2)
variance = cumsum(eigValues)/sum(eigValues)
k = NULL
for(i in 1:length(variance)){
if(variance[i] >= 0.95){
k = i
print(k)
break
}
}
k_selected = eigVectors[, 1:k]
proy_data = as.data.frame(as.matrix(x_data) %*% as.matrix(k_selected))
all_data = cbind(y_data, proy_data)
rand_data = all_data[sample(nrow(all_data)),]
#Del csv sacar el mejor modelo
folds = cut(seq(1, nrow(rand_data)), breaks = 10, labels = F)
recall = c()
accuracy = c()
precision = c()
auc = c()
loss = c()
pred_vector = rep(0, nrow(all_data))
real_vector = rand_data$class
history = c()
for(i in 1:10){
test_index = which(folds == i, arr.ind = T)
test_x = as.matrix(rand_data[test_index, 2:ncol(rand_data)])
test_y = rand_data[test_index, 1]
train_x = as.matrix(rand_data[-test_index, 2:ncol(rand_data)])
train_y = rand_data[-test_index, 1]
test_y = to_categorical(test_y)
train_y = to_categorical(train_y)
model = keras_model_sequential()
model %>%
layer_dense(units = 15, activation = 'relu', input_shape = c(ncol(train_x))) %>%
layer_dense(units = 4, activation = 'softmax')
model %>%
compile(loss = 'categorical_crossentropy',
optimizer = optimizer_adam(lr = 0.005),
metrics = c('accuracy', tf$keras$metrics$AUC(), tf$keras$metrics$Precision(), tf$keras$metrics$Recall()))
mymodel = model %>%
fit(train_x,
train_y,
epochs = 150,
batch_size = 32,
validation_split = 0.2,
callbacks = list(
callback_model_checkpoint("checkpoints.h5"),
callback_early_stopping(
monitor = "val_loss",
min_delta = 0,
patience = 10,
verbose = 0,
mode = c("auto", "min", "max"),
baseline = NULL,
restore_best_weights = T
)
)
)
eval = model %>%
evaluate(test_x,
test_y)
history = c(history, mymodel)
recall = c(recall, eval[5])
accuracy = c(accuracy, eval[2])
precision = c(precision, eval[4])
auc = c(auc, eval[3])
loss = c(loss, eval[1])
pred = model %>% predict_classes(test_x)
pred_vector[test_index] = pred
}
sprintf("Accuracy   Mean: %f   SD: %f", mean(accuracy), sd(accuracy))
sprintf("Precision   Mean: %f   SD: %f", mean(precision), sd(precision))
sprintf("Recall   Mean: %f   SD: %f", mean(recall), sd(recall))
sprintf("AUC   Mean: %f   SD: %f", mean(auc), sd(auc))
sprintf("Loss   Mean: %f   SD: %f", mean(loss), sd(loss))
table(pred_vector, real_vector)

y_data$diagnosis = as.numeric(y_data$diagnosis) - 1 # M:1, B:0
#PCA
mean_x = colMeans(x_data)
for(i in 1:nrow(x_data)){
x_data[i, ] = x_data[i, ] - mean_x
}
svd = svd(x_data)
eigenValues = svd$d^2/ sum(svd$d^2)
eigenVectors = svd$v
variance = cumsum(eigenValues)/sum(eigenValues)
k = NULL
for(i in 1:length(variance)){
if(variance[i] >= 0.95){
k = i
print(k)
break
}
}
k_selected = eigenVectors[,1:k]
proy_data = as.data.frame(as.matrix(x_data) %*% as.matrix(k_selected))
all_data = cbind(y_data, proy_data)
rand_data = all_data[sample(nrow(all_data)),]
#Del csv sacar el mejor modelo
folds = cut(seq(1, nrow(rand_data)), breaks = 10, labels = F)
recall = c()
accuracy = c()
precision = c()
auc = c()
loss = c()
pred_vector = rep(0, nrow(all_data))
real_vector = rand_data$diagnosis
history = c()
for(i in 1:10){
test_index = which(folds == i, arr.ind = T)
test_x = as.matrix(rand_data[test_index, 2:ncol(rand_data)])
test_y = as.matrix(rand_data[test_index, 1])
train_x = as.matrix(rand_data[-test_index, 2:ncol(rand_data)])
train_y = as.matrix(rand_data[-test_index, 1])
model = keras_model_sequential()
model %>%
layer_dense(units = 100, activation = 'relu', input_shape = c(ncol(train_x))) %>%
layer_dense(units = 50, activation = 'relu') %>%
layer_dense(units = 1, activation = 'sigmoid')
model %>%
compile(loss = 'binary_crossentropy',
optimizer = optimizer_rmsprop(lr = 0.001),
metrics = c('accuracy', tf$keras$metrics$AUC(), tf$keras$metrics$Precision(), tf$keras$metrics$Recall()))
mymodel = model %>%
fit(train_x,
train_y,
epochs = 50,
batch_size = 32,
validation_split = 0.2
)
eval = model %>%
evaluate(test_x,
test_y)
history = c(history, mymodel)
recall = c(recall, eval[5])
accuracy = c(accuracy, eval[2])
precision = c(precision, eval[4])
auc = c(auc, eval[3])
loss = c(loss, eval[1])
prob = model %>%
predict(test_x)
pred = ifelse(prob <= 0.5, 0, 1)
pred_vector[test_index] = pred
}
sprintf("Accuracy   Mean: %f   SD: %f", mean(accuracy), sd(accuracy))
sprintf("Precision   Mean: %f   SD: %f", mean(precision), sd(precision))
sprintf("Recall   Mean: %f   SD: %f", mean(recall), sd(recall))
sprintf("AUC   Mean: %f   SD: %f", mean(auc), sd(auc))
sprintf("Loss   Mean: %f   SD: %f", mean(loss), sd(loss))
table(pred_vector, real_vector)
precrec_obj <- evalmod(scores = pred_vector, labels = real_vector)
plot(precrec_obj)
precrec_obj
#Grafica Loss
length(history)
history[1]
history[1]$params
history[1]$params$epochs
history[2]$metrics$loss
history[2]$metrics$val_loss
library(ggplot2)
epochs = history[1]$params$epochs
loss = history[2]$metrics$loss
val_loss = history[2]$metrics$val_loss
library(ggplot2)
data = data_frame(1:epochs, loss, val_loss)
data = data.frame(1:epochs, loss, val_loss)
View(data)
ggplot() %>%
geom_line(data, aes(x = epochs, y = loss), color = "blue") %>%
geom_line(data, aes(x = epochs, y = val_loss), color = "green")
ggplot() +
geom_line(data, aes(x = epochs, y = loss), color = "blue") +
geom_line(data, aes(x = epochs, y = val_loss), color = "green")
ggplot(data) +
geom_line(aes(x = epochs, y = loss), color = "blue") +
geom_line(aes(x = epochs, y = val_loss), color = "green")
ggplot(data) +
geom_line(aes(x = 1:epochs, y = loss), color = "blue") +
geom_line(aes(x = 1:epochs, y = val_loss), color = "green")
epochs = history[3]$params$epochs
loss = history[4]$metrics$loss
val_loss = history[4]$metrics$val_loss
library(ggplot2)
data = data.frame(1:epochs, loss, val_loss)
ggplot(data) +
geom_line(aes(x = 1:epochs, y = loss), color = "blue") +
geom_line(aes(x = 1:epochs, y = val_loss), color = "green")
seq(1, 10, by = 1)
seq(1, 10, by = 2)
for(i in seq(1, 10, by = 2)){
print(i)
}
epochs = NULL
for(i in seq(1, 20, by = 2)){
epochs = epochs + history[i]$params$epochs
}
epochs
seq(1, 20, by = 2)
seq(1, 20, by = 1)
seq(2, 20, by = 1)
seq(2, 20, by = 2)
data_loss = NULL
data_loss_val = NULL
for(i in seq(1, 20, by = 2)){
data_loss = rbind(data_loss, history[i]$metrics$loss)
data_loss_val = rbind(data_loss_val, history[i]$metrics$val_loss)
}
data_loss = NULL
data_loss_val = NULL
for(i in seq(1, 20, by = 2)){
data_loss = rbind(data_loss, as.vector(history[i]$metrics$loss))
data_loss_val = rbind(data_loss_val, as.vector(history[i]$metrics$val_loss))
}
data_loss = NULL
data_loss_val = NULL
for(i in seq(2, 20, by = 2)){
data_loss = rbind(data_loss, as.vector(history[i]$metrics$loss))
data_loss_val = rbind(data_loss_val, as.vector(history[i]$metrics$val_loss))
}
View(data_loss)
mean_loss = colMeans(data_loss)
mean_loss_val = colMeans(data_loss_val)
loss_data = data.frame(mean_loss, mean_loss_val)
View(loss_data)
library(ggplot2)
ggplot(loss_data) +
geom_line(aes(x = 1:nrow(loss_data), y = mean_loss), color = "blue") +
geom_line(aes(x =  1:nrow(loss_data), y = mean_loss_val), color = "green")
library(readr)
data = read_csv("/home/marlon/mainfolder/marlon/USFQ/DataMining/10_FinalProject/proyectoFinal/Model_1/ANN_models/scores.csv")
View(data)
library(keras)
library(readr)
library(dplyr)
library(tensorflow)
library(precrec)
dataset <- read_csv("/home/marlon/mainfolder/marlon/USFQ/DataMining/10_FinalProject/proyectoFinal/Model_1/dataset/wdbc.data",
col_names = FALSE)
dataset = dataset %>%
select(-1) %>%
rename("diagnosis" = X2)
for(i in 2:ncol(dataset)){
dataset[i] =  (dataset[i] - min(dataset[i]))/ (max(dataset[i]) - min(dataset[i])) * (1-0) + 0
}
x_data = dataset[, 2:ncol(dataset)]
y_data = dataset[, 1]
y_data$diagnosis = as.factor(y_data$diagnosis)
y_data$diagnosis = as.numeric(y_data$diagnosis) - 1 # M:1, B:0
#PCA
mean_x = colMeans(x_data)
for(i in 1:nrow(x_data)){
x_data[i, ] = x_data[i, ] - mean_x
}
svd = svd(x_data)
eigenValues = svd$d^2/ sum(svd$d^2)
eigenVectors = svd$v
variance = cumsum(eigenValues)/sum(eigenValues)
k = NULL
for(i in 1:length(variance)){
if(variance[i] >= 0.95){
k = i
print(k)
break
}
}
k_selected = eigenVectors[,1:k]
proy_data = as.data.frame(as.matrix(x_data) %*% as.matrix(k_selected))
all_data = cbind(y_data, proy_data)
rand_data = all_data[sample(nrow(all_data)),]
#Del csv sacar el mejor modelo
folds = cut(seq(1, nrow(rand_data)), breaks = 10, labels = F)
recall = c()
accuracy = c()
precision = c()
auc = c()
loss = c()
pred_vector = rep(0, nrow(all_data))
real_vector = rand_data$diagnosis
history = c()
for(i in 1:10){
test_index = which(folds == i, arr.ind = T)
test_x = as.matrix(rand_data[test_index, 2:ncol(rand_data)])
test_y = as.matrix(rand_data[test_index, 1])
train_x = as.matrix(rand_data[-test_index, 2:ncol(rand_data)])
train_y = as.matrix(rand_data[-test_index, 1])
model = keras_model_sequential()
model %>%
layer_dense(units = 100, activation = 'relu', input_shape = c(ncol(train_x))) %>%
layer_dense(units = 50, activation = 'relu') %>%
layer_dense(units = 1, activation = 'sigmoid')
model %>%
compile(loss = 'binary_crossentropy',
optimizer = optimizer_rmsprop(lr = 0.005),
metrics = c('accuracy', tf$keras$metrics$AUC(), tf$keras$metrics$Precision(), tf$keras$metrics$Recall()))
mymodel = model %>%
fit(train_x,
train_y,
epochs = 100,
batch_size = 32,
validation_split = 0.2
)
eval = model %>%
evaluate(test_x,
test_y)
history = c(history, mymodel)
recall = c(recall, eval[5])
accuracy = c(accuracy, eval[2])
precision = c(precision, eval[4])
auc = c(auc, eval[3])
loss = c(loss, eval[1])
prob = model %>%
predict(test_x)
pred = ifelse(prob <= 0.5, 0, 1)
pred_vector[test_index] = pred
}
sprintf("Accuracy   Mean: %f   SD: %f", mean(accuracy), sd(accuracy))
sprintf("Precision   Mean: %f   SD: %f", mean(precision), sd(precision))
sprintf("Recall   Mean: %f   SD: %f", mean(recall), sd(recall))
sprintf("AUC   Mean: %f   SD: %f", mean(auc), sd(auc))
sprintf("Loss   Mean: %f   SD: %f", mean(loss), sd(loss))
table(pred_vector, real_vector)
precrec_obj <- evalmod(scores = pred_vector, labels = real_vector)
plot(precrec_obj)
precrec_obj
#Grafica Loss
data_loss = NULL
data_loss_val = NULL
for(i in seq(2, 20, by = 2)){
data_loss = rbind(data_loss, as.vector(history[i]$metrics$loss))
data_loss_val = rbind(data_loss_val, as.vector(history[i]$metrics$val_loss))
}
mean_loss = colMeans(data_loss)
mean_loss_val = colMeans(data_loss_val)
loss_data = data.frame(mean_loss, mean_loss_val)
library(ggplot2)
ggplot(loss_data) +
geom_line(aes(x = 1:nrow(loss_data), y = mean_loss), color = "blue") +
geom_line(aes(x =  1:nrow(loss_data), y = mean_loss_val), color = "green")
library(keras)
library(readr)
library(dplyr)
library(tensorflow)
library(precrec)
dataset <- read_csv("/home/marlon/mainfolder/marlon/USFQ/DataMining/10_FinalProject/proyectoFinal/Model_1/dataset/wdbc.data",
col_names = FALSE)
dataset = dataset %>%
select(-1) %>%
rename("diagnosis" = X2)
for(i in 2:ncol(dataset)){
dataset[i] =  (dataset[i] - min(dataset[i]))/ (max(dataset[i]) - min(dataset[i])) * (1-0) + 0
}
x_data = dataset[, 2:ncol(dataset)]
y_data = dataset[, 1]
y_data$diagnosis = as.factor(y_data$diagnosis)
y_data$diagnosis = as.numeric(y_data$diagnosis) - 1 # M:1, B:0
#PCA
mean_x = colMeans(x_data)
for(i in 1:nrow(x_data)){
x_data[i, ] = x_data[i, ] - mean_x
}
svd = svd(x_data)
eigenValues = svd$d^2/ sum(svd$d^2)
eigenVectors = svd$v
variance = cumsum(eigenValues)/sum(eigenValues)
k = NULL
for(i in 1:length(variance)){
if(variance[i] >= 0.95){
k = i
print(k)
break
}
}
k_selected = eigenVectors[,1:k]
proy_data = as.data.frame(as.matrix(x_data) %*% as.matrix(k_selected))
all_data = cbind(y_data, proy_data)
rand_data = all_data[sample(nrow(all_data)),]
folds = cut(seq(1, nrow(rand_data)), breaks = 10, labels = F)
recall = c()
accuracy = c()
precision = c()
auc = c()
loss = c()
pred_vector = rep(0, nrow(all_data))
real_vector = rand_data$diagnosis
history = c()
for(i in 1:10){
test_index = which(folds == i, arr.ind = T)
test_x = as.matrix(rand_data[test_index, 2:ncol(rand_data)])
test_y = as.matrix(rand_data[test_index, 1])
train_x = as.matrix(rand_data[-test_index, 2:ncol(rand_data)])
train_y = as.matrix(rand_data[-test_index, 1])
model = keras_model_sequential()
model %>%
layer_dense(units = 100, activation = 'relu', input_shape = c(ncol(train_x))) %>%
layer_dense(units = 1, activation = 'sigmoid')
model %>%
compile(loss = 'binary_crossentropy',
optimizer = optimizer_rmsprop(lr = 0.001),
metrics = c('accuracy', tf$keras$metrics$AUC(), tf$keras$metrics$Precision(), tf$keras$metrics$Recall()))
mymodel = model %>%
fit(train_x,
train_y,
epochs = 100,
batch_size = 32,
validation_split = 0.2
)
eval = model %>%
evaluate(test_x,
test_y)
history = c(history, mymodel)
recall = c(recall, eval[5])
accuracy = c(accuracy, eval[2])
precision = c(precision, eval[4])
auc = c(auc, eval[3])
loss = c(loss, eval[1])
prob = model %>%
predict(test_x)
pred = ifelse(prob <= 0.5, 0, 1)
pred_vector[test_index] = pred
}
sprintf("Accuracy   Mean: %f   SD: %f", mean(accuracy), sd(accuracy))
sprintf("Precision   Mean: %f   SD: %f", mean(precision), sd(precision))
sprintf("Recall   Mean: %f   SD: %f", mean(recall), sd(recall))
sprintf("AUC   Mean: %f   SD: %f", mean(auc), sd(auc))
sprintf("Loss   Mean: %f   SD: %f", mean(loss), sd(loss))
table(pred_vector, real_vector)
precrec_obj <- evalmod(scores = pred_vector, labels = real_vector)
plot(precrec_obj)
precrec_obj
library(ggplot2)
ggplot(loss_data) +
geom_line(aes(x = 1:nrow(loss_data), y = mean_loss), color = "blue") +
geom_line(aes(x =  1:nrow(loss_data), y = mean_loss_val), color = "green")+
xlab("Epochs") + ylab("Loss") + labs(title = "Loss")
data_loss = NULL
data_loss_val = NULL
for(i in seq(2, 20, by = 2)){
data_loss = rbind(data_loss, as.vector(history[i]$metrics$loss))
data_loss_val = rbind(data_loss_val, as.vector(history[i]$metrics$val_loss))
}
mean_loss = colMeans(data_loss)
mean_loss_val = colMeans(data_loss_val)
loss_data = data.frame(mean_loss, mean_loss_val)
library(ggplot2)
ggplot(loss_data) +
geom_line(aes(x = 1:nrow(loss_data), y = mean_loss), color = "blue") +
geom_line(aes(x =  1:nrow(loss_data), y = mean_loss_val), color = "green")+
xlab("Epochs") + ylab("Loss") + labs(title = "Loss")
library(readr)
library(dplyr)
library(e1071)
library(precrec)
library(vtreat)
library(pROC)
dataset <- read_csv("/home/marlon/mainfolder/marlon/USFQ/DataMining/10_FinalProject/proyectoFinal/Model_1/dataset/wdbc.data",
col_names = FALSE)
dataset = dataset %>%
select(-X1) %>%
rename("diagnosis" = X2)
dataset$diagnosis = as.factor(dataset$diagnosis)
dataset %>%
select(diagnosis) %>%
group_by(diagnosis) %>%
summarise(n = n())
#Normalize the data
summary(dataset)
for(i in 2:ncol(dataset)){
dataset[i] =  (dataset[i] - min(dataset[i]))/ (max(dataset[i]) - min(dataset[i])) * (1-0) + 0
}
summary(dataset)
x_data = dataset[, 2:ncol(dataset)]
y_data = dataset[, 1]
#Dimensionality reduction
mean_row = colMeans(x_data)
for(i in 1:nrow(x_data)){
x_data[i, ] = x_data[i, ] - mean_row
}
svd = svd(x_data)
eigVectors = svd$v
eigValues = svd$d^2/sum(svd$d^2)
variance = cumsum(eigValues)/sum(eigValues)
k = NULL
for(i in 1:length(variance)){
if(variance[i] >= 0.95){
k = i
print(k)
break
}
}
k_selected = eigVectors[, 1:k]
proy_data = as.data.frame(as.matrix(x_data) %*% as.matrix(k_selected))
final_data = cbind(y_data, proy_data)
#tunning
gamma_list = 5*10^(-2:2)
cost_list = c(0.01, 0.1, 1, 10, 100)
kernel_list = c("radial", "linear", "polynomial")
splitPlan = kWayCrossValidation(nRows = nrow(final_data), 10, NULL, NULL)
gen_acc = c()
gen_auc = c()
gen_pre = c()
gen_rec = c()
gen_gamma = c()
gen_cost = c()
gen_kernel = c()
for(gm in gamma_list){
for(cos in cost_list){
for(ker in kernel_list){
recall = c()
accuracy = c()
precision = c()
auc = c()
for(i in 1:10){
split = splitPlan[[i]]
svm_model = svm(diagnosis~ ., data = final_data[split$train, ], type = "C-classification",
kernel = ker,
cost = cos,
gamma = gm)
pred = predict(svm_model, final_data[split$app, ])
real = final_data[split$app, ]$diagnosis
confusion = as.matrix(table(real, pred))
diag = diag(confusion)
colsums = apply(confusion, 2, sum)
rowsums = apply(confusion, 1, sum)
n = sum(confusion)
recall[i] = diag / rowsums
precision[i] = diag / colsums
accuracy[i] = sum(diag) / n
x = roc(as.numeric(real), (as.numeric(pred) - 1))
auc[i] = x$auc
}
gen_acc = c(gen_acc, mean(accuracy))
gen_auc = c(gen_auc, mean(auc))
gen_pre = c(gen_pre, mean(precision))
gen_rec = c(gen_rec, mean(recall))
gen_gamma = c(gen_gamma, gm)
gen_cost = c(gen_cost, cos)
gen_kernel = c(gen_kernel, ker)
}
}
}
score_svm = data.frame(gen_kernel, gen_gamma, gen_cost, gen_acc, gen_auc, gen_pre, gen_rec)
write_csv(score_svm, "/home/marlon/mainfolder/marlon/USFQ/DataMining/10_FinalProject/proyectoFinal/Model_1/score_svm.csv")
best_model = score_svm %>%
arrange(desc(gen_auc))
best_model = best_model[1, ]
best_gamma = best_model[, 2]
best_cost = best_model[,3]
best_kernel = best_model[,1]
splitPlan = kWayCrossValidation(nRows = nrow(final_data), 10, NULL, NULL)
recall = c()
accuracy = c()
precision = c()
auc = c()
pred_vector = rep(0, nrow(final_data))
for(i in 1:10){
split = splitPlan[[i]]
svm_model = svm(diagnosis~ ., data = final_data[split$train, ], type = "C-classification", kernel = best_kernel,
cost = best_cost,
gamma = best_gamma)
pred_vector[split$app] = predict(svm_model, final_data[split$app, ])
pred = predict(svm_model, final_data[split$app, ])
real = final_data[split$app, ]$diagnosis
confusion = as.matrix(table(real, pred))
diag = diag(confusion)
colsums = apply(confusion, 2, sum)
rowsums = apply(confusion, 1, sum)
n = sum(confusion)
recall[i] = diag / rowsums
precision[i] = diag / colsums
accuracy[i] = sum(diag) / n
x = roc(as.numeric(real), (as.numeric(pred) - 1))
auc[i] = x$auc
}
sprintf("Accuracy   Mean: %f   SD: %f", mean(accuracy), sd(accuracy))
sprintf("Precision   Mean: %f   SD: %f", mean(precision), sd(precision))
sprintf("Recall   Mean: %f   SD: %f", mean(recall), sd(recall))
sprintf("AUC   Mean: %f   SD: %f", mean(auc), sd(auc))
real_vector = final_data$diagnosis
table(pred_vector, real_vector)
pred_vector
real_vector
plot(svm_model, final_data[split$train, ], V1 ~ V2)
plot(svm_model, final_data[split$train, ], V4 ~ V2)
plot(svm_model, final_data[split$train, ], V1 ~ V2)
plot(svm_model, final_data[split$train, ], V3 ~ V2)
plot(svm_model, final_data[split$train, ], V5 ~ V2)
plot(svm_model, final_data[split$train, ], V1 ~ V2)
